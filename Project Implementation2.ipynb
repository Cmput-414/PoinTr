{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cmput-414/PoinTr/blob/master/Project%20Implementation2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1: Set environments**\n",
        "\n"
      ],
      "metadata": {
        "id": "inDyCMC7m7wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################Step 1: Git clone code ##################################################\n",
        "# 1. we clone the code from the github.\n",
        "# 2. This will create a directory /content/pointr\n",
        "!git -C /content/ clone https://github.com/Cmput-414/PoinTr.git pointr\n",
        "########################################################################################################################################\n",
        "\n",
        "##########################################################Step 2: Install conda ####################################################\n",
        "# 1. Install conda environment for later use.\n",
        "# 2. We will use conda to install a vitural environments with python 3.6\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.12.0-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py37_4.12.0-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-py37_4.12.0-Linux-x86_64.sh -b -f -p /usr/local/\n",
        "!conda create --no-default-packages -n myenv python=3.6 --yes\n",
        "########################################################################################################################################\n",
        "\n",
        "##########################################################Step 3: set virtual environment #########################################\n",
        "# 1. After we set virtual environmentï¼Œ we activate it, check if we are in correct environment.\n",
        "# 2. Then we install correct cuda version and pytorch version.\n",
        "# 3. Then we will start to install some other packages. (This step will take some times, around 10 minutes.\n",
        "!source activate myenv && which python && conda install pytorch==1.4.0 torchvision==0.5.0 cudatoolkit=10.0 -c pytorch -y\n",
        "!source activate myenv && pip install ninja\n",
        "!source activate myenv && git config --global url.\"https://\".insteadOf git://\n",
        "!source activate myenv && pip install \"git+git://github.com/erikwijmans/Pointnet2_PyTorch.git#egg=pointnet2_ops&subdirectory=pointnet2_ops_lib\"\n",
        "!source activate myenv && pip install --upgrade https://github.com/unlimblue/KNN_CUDA/releases/download/0.1/KNN_CUDA-0.1-py3-none-any.whl\n",
        "%cd /content/pointr\n",
        "!source activate myenv && pip install -r requirements.txt\n",
        "!source activate myenv && cd /content/pointr/extensions/chamfer_dist && python setup.py install --user\n",
        "!source activate myenv && cd /content/pointr/extensions/cubic_feature_sampling && python setup.py install --user\n",
        "!source activate myenv && cd /content/pointr/extensions/gridding && python setup.py install --user \n",
        "!source activate myenv && cd /content/pointr/extensions/gridding_loss && python setup.py install --user\n",
        "########################################################################################################################################"
      ],
      "metadata": {
        "id": "1BtAS4sKG6m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2: Set dataset**"
      ],
      "metadata": {
        "id": "lENkEEq8nBLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Please check your email, we send a shared google drive that contain the dataset.\n",
        "# If you will not see that shared drive, you can download teh dataset from README.md / new_data.md\n",
        "##################################################Step 1: Connect shared drive ####################################################\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rSyNIHd_5wvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytRHN4f42KnI"
      },
      "outputs": [],
      "source": [
        "# After set environment, we will start set dataset\n",
        "# In this project, we will use KITTI and PCN dataset\n",
        "##################################################Step 1: KITTI dataset ############################################################\n",
        "#https://drive.google.com/file/d/1Vvci0uu-eAKsBrDEwJWWBP_r9qr_eHzI/view?usp=share_link\n",
        "\n",
        "!cp -r '/content/drive/Shareddrives/Pointr/kitti/bboxes' /content/pointr/data/KITTI\n",
        "!cp -r '/content/drive/Shareddrives/Pointr/kitti/cars' /content/pointr/data/KITTI\n",
        "!cp -r '/content/drive/Shareddrives/Pointr/kitti/tracklets' /content/pointr/data/KITTI\n",
        "########################################################################################################################################\n",
        "\n",
        "##################################################Step 2: PCN dataset ##############################################################\n",
        "# https://drive.google.com/file/d/1-L2bqK2dRMjSkDR8K6LEe_ad6JFT3kwj/view?usp=share_link\n",
        "\n",
        "!unzip /content/drive/Shareddrives/Pointr/PCN.zip -d / \n",
        "########################################################################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 3: Train code**\n",
        "In this step: we will get some check points, then we can use these check points to do test. Finally, we can get visual result from the training result."
      ],
      "metadata": {
        "id": "BAqtdrHTmHWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/pointr\n",
        "# You can change KITTI_models to PCN_models to train PCN dataset.\n",
        "# The check point will save in to new direcory: ./experiments\n",
        "# For example: save ckpt for KITTI\n",
        "# /content/pointr/experiments/PoinTr/KITTI_models/example\n",
        "# For example: save ckpt for PCN\n",
        "# /content/pointr/experiments/PoinTr/PCN_models/example\n",
        "# Our training based on PoinTr.yaml.\n",
        "# PoinTr.yaml contain the information about total batch size(total_bs) and epoch. \n",
        "# You can change the batch size and epoch number before start training.\n",
        "# For KITTI dataset, The PoinTr.yaml located in /content/pointr/cfgs/KITTI_models/PoinTr.yaml\n",
        "# For PCN dataset, The PoinTr.yaml located in /content/pointr/cfgs/PCN_models/PoinTr.yaml\n",
        "# You can move the mouse pointer to the above link, click it will direct you to that position. (Or press ctrl + click)\n",
        "\n",
        "!source activate myenv && which python && bash ./scripts/train.sh 0 --config ./cfgs/KITTI_models/PoinTr.yaml --exp_name example"
      ],
      "metadata": {
        "id": "AO7DSws-8EWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 4: Test code**\n",
        "In this step, we use training result to do test, and get some visual result.\n",
        "Alternatively,we provide some pretrain model to do evaluation."
      ],
      "metadata": {
        "id": "RHG0TZwrl3P6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/pointr\n",
        "# You can choose one of check point to test.\n",
        "# Our test based on PoinTr.yaml and check point from training.\n",
        "# PoinTr.yaml contain the information about total batch size(total_bs) and epoch. \n",
        "# You can change the batch size and epoch number before start testing.\n",
        "# Test and training should keep same batch size and epoch number.\n",
        "# Find ckpt on ./experiements folder\n",
        "# For example: load ckpt for KITTI\n",
        "# /content/pointr/experiments/PoinTr/KITTI_models/example/ckpt-best.pth\n",
        "# For example: load ckpt for PCN\n",
        "# /content/pointr/experiments/PoinTr/PCN_models/example/ckpt-best.pth\n",
        "!source activate myenv && which python && bash ./scripts/test.sh 0 --ckpts ./experiments/PoinTr/KITTI_models/example/ckpt-best.pth --config ./cfgs/KITTI_models/PoinTr.yaml --exp_name example"
      ],
      "metadata": {
        "id": "pvdG0tgcHvIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/pointr\n",
        "# You can choose one of pretrained model to test.\n",
        "# PoinTr.yaml contain the information about total batch size(total_bs) and epoch. \n",
        "# You cannot change the batch size and epoch number before start testing.\n",
        "# Test should keep same batch size and epoch number with pretrained model.\n",
        "# Download pretrained model on ./pretrained folder\n",
        "!unzip /content/drive/Shareddrives/Pointr/pretrain/kitti-ckpt_best.pth -d /content/pointr/pretrained\n",
        "!unzip /content/drive/Shareddrives/Pointr/pretrain/pcn-ckpt_best.pth -d /content/pointr/pretrained\n",
        "# For example: load pretrained model for KITTI\n",
        "# /content/pointr/pretrained/kitti-ckpt-best.pth\n",
        "# For example: load pretrained model for PCN\n",
        "# /content/pointr/pretrained/pcn-ckpt-best.pth\n",
        "!source activate myenv && which python && bash ./scripts/test.sh 0 --ckpts ./pretrained/kitti-ckpt-best.pth --config ./cfgs/KITTI_models/PoinTr.yaml --exp_name example"
      ],
      "metadata": {
        "id": "-6JFbGOoayOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra step: See visual result"
      ],
      "metadata": {
        "id": "ChXn4oMCMDB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run below code to see a gif image for the visual result.\n",
        "# If you test PCN dataset, you should change KITTI_models to PCN_models\n",
        "# The gif image will save into /content/pointr/visual_result.gif\n",
        "# You can move the mouse pointer to the above link, click it will direct you to that position. (Or press ctrl + click)\n",
        "\n",
        "import glob\n",
        "from PIL import Image\n",
        "fp_in = \"/content/pointr/experiments/PoinTr/KITTI_models/test_example/vis_result/*.png\"\n",
        "fp_out=\"/content/pointr/visual_result.gif\"\n",
        "# https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html#gif\n",
        "imgs = (Image.open(f) for f in glob.glob(fp_in))\n",
        "img = next(imgs)  # extract first image from iterator\n",
        "img.save(fp=fp_out, format='GIF', append_images=imgs,\n",
        "         save_all=True, duration=200, loop=0)"
      ],
      "metadata": {
        "id": "cIT77i7myqfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run below code to see video for the visual images.\n",
        "# The code combine all images to a video. \n",
        "# The video will save into /content/pointr/video.avi\n",
        "# You can move the mouse pointer to the above link, click it will direct you to that position. (Or press ctrl + click)\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "image_folder = '/content/pointr/experiments/PoinTr/KITTI_models/test_example/vis_result/'\n",
        "video_name = 'video.avi'\n",
        "\n",
        "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
        "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "height, width, layers = frame.shape\n",
        "\n",
        "video = cv2.VideoWriter(video_name, 0, 1, (width,height))\n",
        "\n",
        "for image in images:\n",
        "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "video.release()"
      ],
      "metadata": {
        "id": "M7Ouiiva4fTW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
